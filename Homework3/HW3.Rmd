---
title: "Multiple linear regression and binary logistic regression models"
author: "Abdellah AitElmouden | Gabriel Abreu |  Jered Ataky | Patrick Maloney"
date: "4/13/2021"
output:
  pdf_document: 
    latex_engine: xelatex
    
  
---
```{r include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}

library(corrplot)
library(tidyverse)
library(Hmisc)
library(PerformanceAnalytics)
library(mice)
library(gt)
library(DMwR2)
library(caret)
library(bnstruct)
library(VIM)
library(corrr)
library(gtsummary)
library(kableExtra)
library(naniar)
library(rpart)

```


## Abstract


```{r include=true}

#Import data 

raw_train_data <- read.csv("https://raw.githubusercontent.com/aaitelmouden/DATA621/master/Homework3/crime-training-data_modified.csv")
glimpse(train_data)

#Find any NA values in data
sum(is.na(train_data))


#train_data <- raw_train_data[-13]

```
\newpage




```{r echo=FALSE, message=FALSE, warning=FALSE}

# Summary table 


table1 <- tbl_summary(raw_train_data,
          statistic = list(all_continuous() ~ "{mean} ({sd}) {median} {min} {max}"), missing = "no") 
table1
```


```{r}
raw_train_data$target <- factor(raw_train_data$target)


violin <- ggplot(raw_train_data, aes(x=target, y=rad)) + 
  geom_violin()

violin
```

### Outliers

The following diagram shows the outliers for all the variables, both dependent and independent.

```{r echo=FALSE, message=FALSE, warning=FALSE}

ggplot(stack(raw_train_data[-13]), aes(x = ind, y = values, fill=ind)) + 
  geom_boxplot(outlier.colour = "red",  outlier.alpha=.4) +
  coord_cartesian(ylim = c(0, 1000)) +
  theme_classic()+
  theme(axis.text.x=element_text(angle=45, hjust=1)) 
```





### Correlations among predictors and Variable Selection



```{r echo=FALSE, message=FALSE, warning=FALSE}

COR <- raw_train_data %>% 
  correlate() %>% 
  focus(target)
gt(COR)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
COR %>% 
  mutate(rowname = factor(term, levels = term[order(target)])) %>%  # Order by correlation strength
  ggplot(aes(x = rowname, y = target)) +
    geom_bar(stat = "identity") +
    ylab("Correlation with TARGET WINS") +
    xlab("Variables") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ ggtitle("Figure 4: Correlation Against Target Win")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}

#pairwise.complete.obs ignores NA values and computes correlation on complete observations
#we might have to run these corrplots again after we handle the NA values
chart.Correlation(raw_train_data, histograme=TRUE, method= "pearson", use="pairwise.complete.obs")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
data.corr <- cor(train_data[-c(1)], use="pairwise.complete.obs")

corrplot(data.corr, type = "lower", method="square")
```


```{r, include = FALSE}
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}
```


```{r include=FALSE}
#eliminate INDEX from data frame
data_no_index <- train_data[-c(1)]

cor_matrix <- rcorr(as.matrix(data_no_index))

flattenCorrMatrix(cor_matrix$r, cor_matrix$P)
```


## Data Preparation


```{r echo=FALSE, message=FALSE, warning=FALSE}
train_data <- train_data[-11]
```



```{r echo=FALSE, message=FALSE, warning=FALSE}


par(mfrow=c(1,2))
gg_miss_upset(train_data, 
              nsets = 5,
              nintersects = NA)
gg_miss_case(train_data)+
  theme_classic()
```






\begin{center}
Mean (SD) Median Minimum Maximum 
\end{center}


